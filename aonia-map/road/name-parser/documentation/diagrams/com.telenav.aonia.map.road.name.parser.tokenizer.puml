@startuml

    !include ../lexakai/lexakai.theme
    
    title "com.telenav.aonia.map.road.name.parser.tokenizer"
    
    interface Iterable
    
    class TokenList.Builder
    {
        --(collection)--
        +Builder add(Token)
        +TokenList build()
    }
    
    class Token
    {
        --
        +Token matches(String symbol, TokenMatcher)
        +Token matches(Symbol, TokenMatcher)
        +Token matchesAnyOf(String... values)
        +Token matchesSequence(String... words)
        +Token of(SymbolStream)
        +String text()
        --(checks)--
        +boolean isDash()
        +boolean isDot()
        +boolean isSlash()
        +boolean isWhitespace()
        +boolean isWord()
        --(collection)--
        +Token addTo(Set<Token> tokens)
        +int symbolCount()
        --(identity)--
        +int identifier()
        --(naming)--
        +String name()
    }
    
    Iterable <|-- TokenList
    class TokenList
    {
        --
        +void at(int at)
        +int at()
        +Token current()
        +Token get(int index)
        +boolean lookingAt(Token)
        +int previous()
        +String rawText()
        +String remainder()
        +String remainderCapitalized()
        +void skipAny(Token)
        +Token token(int index)
        --(collection)--
        +boolean atLast()
        +Token first()
        +boolean isEmpty()
        +Token last()
        +Token remove(int index)
        +Token removeFirst()
        +Token removeLast()
        +int size()
        +List<? extends Token> tokens()
        --(iteration)--
        +boolean hasMore()
        +void next()
        --(lifecycle)--
        +void reset()
        --(matching)--
        +boolean match(Token)
    }
    
    interface TokenMatcher
    {
        --(matching)--
        +Token match(SymbolStream)
    }
    
    class Tokenizer
    {
        --
        +Token create(String name)
        --(checks)--
        +boolean isDash(Token)
        +boolean isDot(Token)
        +boolean isLetter(Token)
        +boolean isPoundSign(Token)
        +boolean isSemicolon(Token)
        +boolean isSlash(Token)
        --(collection)--
        +TokenList tokenize(String input)
        --(iteration)--
        +Token next(SymbolStream)
    }
    
@enduml

